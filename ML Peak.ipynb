{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e348d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pymzml\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f46f0",
   "metadata": {},
   "source": [
    "# Data processing - From csv to ml input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9fc28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 0.005\n",
    "data_per_sec = 2\n",
    "number_ticks = 240\n",
    "half_time_window = 60 #sec\n",
    " \n",
    "data_train = './train.csv'\n",
    "data_test = './test.csv'\n",
    "data_mz = \"./clarkii T0I1.mzML\"\n",
    "\n",
    "data_train2 = './train2.csv'\n",
    "data_test2 = './test2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a91a9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_mz(run ,mz , retention_time):\n",
    "    \n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    ticks_processed = 0\n",
    "    \n",
    "    for i, scan in enumerate(run):\n",
    "        \n",
    "        if scan.ms_level == 1:\n",
    "\n",
    "            t, measure = scan.scan_time  # get scan time\n",
    "\n",
    "            if t >= (retention_time-half_time_window):\n",
    "                \n",
    "                ticks_processed +=1\n",
    "                \n",
    "                mz_in_range = []\n",
    "                for d in scan.peaks('raw'):\n",
    "                    mz_scan = d[0]\n",
    "                    i_scan = d[1]\n",
    "                    \n",
    "                    if mz_scan >= mz - precision  and mz_scan <= mz + precision:\n",
    "                        mz_in_range.append(i_scan)\n",
    "                        \n",
    "                if not mz_in_range:\n",
    "                    data.append(0)\n",
    "                else:\n",
    "                    data.append(mz_in_range[0])\n",
    "                    \n",
    "                if ticks_processed == number_ticks:\n",
    "                    break\n",
    "                                \n",
    "    return data\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449a84fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(x,window_len=11,window='hanning'):\n",
    "    \"\"\"smooth the data using a window with requested size.\n",
    "    \n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal \n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "    \n",
    "    input:\n",
    "        x: the input signal \n",
    "        window_len: the dimension of the smoothing window; should be an odd integer\n",
    "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "\n",
    "    output:\n",
    "        the smoothed signal\n",
    "        \n",
    "    example:\n",
    "\n",
    "    t=linspace(-2,2,0.1)\n",
    "    x=sin(t)+randn(len(t))*0.1\n",
    "    y=smooth(x)\n",
    "    \n",
    "    see also: \n",
    "    \n",
    "    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "    scipy.signal.lfilter\n",
    " \n",
    "    TODO: the window parameter could be the window itself if an array instead of a string\n",
    "    NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    if window_len<3:\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('np.'+window+'(window_len)')\n",
    "\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bda925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(data):\n",
    "    if np.max(data) - np.min(data) == 0.0:\n",
    "        return data\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def build_data_ml(path):\n",
    "    \n",
    "    X_ = []\n",
    "    y_ = []\n",
    "    \n",
    "    run = pymzml.run.Reader(data_mz)\n",
    "    \n",
    "    with open(path, newline='') as f:\n",
    "        reader = csv.reader(f,delimiter=';')\n",
    "        for line in list(reader):\n",
    "            X_train_item = get_data_mz(run, float(line[1]), float(line[2])*60)\n",
    "            y_.append(1 if line[6] == 'YES' else 0)   \n",
    "            \n",
    "            xp = [i for i in range(0,len(X_train_item))]\n",
    "            fp = [i for i in range(0,len(X_train_item))]\n",
    "            X_train_interp = smooth(X_train_item,window='hanning')  #'flat', 'hanning', 'hamming', 'bartlett', 'blackman'          \n",
    "            X_train_norm = NormalizeData(X_train_interp)\n",
    "            X_.append(X_train_norm)\n",
    "            \n",
    "            #plt.plot(X_train_item)\n",
    "            #plt.plot(X_train_norm)\n",
    "            #plt.show()     \n",
    "            \n",
    "    return X_, y_\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "044d7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train) = build_data_ml(data_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ae832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_test, y_test) = build_data_ml(data_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae0e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01f4dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Input\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187252e3",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4324c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5173761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:44:38.283972: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 240, 1)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 10),              480       \n",
      "                              (None, 10),                        \n",
      "                              (None, 10)]                        \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 22        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 505\n",
      "Trainable params: 505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputvec = Input(shape=(240,1))\n",
    "lstm = LSTM(10, activation=\"relu\" ,return_sequences = False , return_state = True, go_backwards = True )\n",
    "whole_seq_output,final_memory_state, final_carry_state = lstm(inputvec)\n",
    "output = Dense(2)(final_memory_state)\n",
    "final = Dense(1,activation = 'sigmoid')(output)\n",
    "model = Model( inputs = inputvec , outputs = final)\n",
    "\n",
    "opt = tf.keras.optimizers.RMSprop( learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9caa00af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 2s 58ms/step - loss: 0.6934 - accuracy: 0.4949\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.6930 - accuracy: 0.5354\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 0.6929 - accuracy: 0.5354\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.6928 - accuracy: 0.5354\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.6927 - accuracy: 0.5354\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.6925 - accuracy: 0.5354\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.6924 - accuracy: 0.5354\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.6923 - accuracy: 0.5354\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.6923 - accuracy: 0.5354\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.6921 - accuracy: 0.5354\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 0.6922 - accuracy: 0.5354\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 1s 60ms/step - loss: 0.6919 - accuracy: 0.5354\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 0.6920 - accuracy: 0.5354\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 0.6919 - accuracy: 0.5354\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.6918 - accuracy: 0.5354\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 0.6916 - accuracy: 0.5354\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.6918 - accuracy: 0.5354\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 0.6916 - accuracy: 0.5354\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 0.6916 - accuracy: 0.5354\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.6914 - accuracy: 0.5354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1473e4d60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sequence.pad_sequences(X_train, maxlen=240)\n",
    "model.fit(x, np.array(y_train), epochs=20, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13205d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.00%\n",
      "[0.6937482953071594, 0.5]\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=240)\n",
    "scores = model.evaluate(x_test, np.array(y_test), verbose=0)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36a8135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7151ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81e0d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e18a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da1336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef3634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92879856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
